{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import random\n",
    "from random import randint\n",
    "from random import choice\n",
    "from random import sample\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's matrix with random weights, and zeros and ones for, respectively, connected/not connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 0.5311419289901855], [1, 0.8044894616753239], [0, 0.5444843351627849]],\n",
       " [[1, 0.12045044983474074], [0, 0.7265048649208496], [1, 0.1719983098440938]],\n",
       " [[1, 0.8400470351907151], [0, 0.32713658984179195], [0, 0.9756085336395302]]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weightedadjacencymatrix = [[[randint(0,1),random()] for i in range(3)] for j in range(3)]\n",
    "weightedadjacencymatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second vertex is not connected to any other vertices. This is a problem, since there are no solutions to the TSP on a disconnected graph.\n",
    "\n",
    "To generate a random graph on which a solution to the TSP is guaranteed to exist, we could:\n",
    "1. iteratively attach vertices to a random number of other vertices\n",
    "2. \"trim\" a fully connected graph, removing a number of edges while\n",
    "    - trimming in pairs, to keep symmetry of adjacency matrix\n",
    "    - leaving at most one vertex with less than two edges, to keep connectedness\n",
    "    - leaving all vertices with at least two edges, for there to be a Hamiltonean path\n",
    "\n",
    "We can think of the first approach as edge-centric, and the second one as vertex-centric. Although either should work, I'll go with the edge-centric one, since it feels more natural to me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Edge-centric approach\n",
    "We build a connected graph by attaching edges to an existing graph. A graph is seen as a collection of edges, an ordered triple consisting of two vertices and a weight (the distance between the vertices). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should we generate the adjacency matrix when needed or update as we add vertices?\n",
    "1. If we generate as needed, there's less computational overhead. But small changes in the graph require the matrix to be fully regenerated\n",
    "2. If we generate as we add edges, there's the advantage of just adding another row+column\n",
    "    1. So I'll go with this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class vertex:\n",
    "    neighbourhood = []\n",
    "    def __init__(self, vertex_name):\n",
    "        # ANY kind of ID. For Heidelberg, could be latitude, longitude, altitude...\n",
    "        self.name = vertex_name\n",
    "    def neighbours(self, vertex):\n",
    "        self.neighbourhood.append(vertex)\n",
    "    def print(self):\n",
    "        print(self.name)        \n",
    "        \n",
    "class edge:\n",
    "    def __init__(self, a, b, w):\n",
    "        self.v1 = a\n",
    "        self.v2 = b\n",
    "        self.weight = w      \n",
    "    def print(self):\n",
    "        print(self.v1.name, \"to\", self.v2.name, \"taking\", self.weight, \"km\")\n",
    "    \n",
    "class graph:\n",
    "    vertices = []\n",
    "    dictio = {}\n",
    "    edges = []\n",
    "    weighted_adjacency_matrix = np.zeros((1)) #adjacency matrix is composed of zeros and weights; implemented as a numpy array\n",
    "    # for convenience\n",
    "    \n",
    "    def __init__(self,v1,v2,w):\n",
    "        #recycling code from attach_vertex below, should be improved\n",
    "        self.edges.append(edge(v1,v2,w))\n",
    "                \n",
    "        self.dictio[v1.name]=len(self.vertices)\n",
    "        self.vertices.append(v1)\n",
    "        self.dictio[v2.name]=len(self.vertices)\n",
    "        self.vertices.append(v2)\n",
    "                \n",
    "        a = (len(self.vertices), len(self.vertices))\n",
    "        \n",
    "        temp_matrix = np.zeros(a)\n",
    "                              \n",
    "        temp_matrix[self.dictio[v1.name], self.dictio[v2.name]] = w\n",
    "        temp_matrix[self.dictio[v2.name], self.dictio[v1.name]] = w\n",
    "\n",
    "        temp_matrix[:-1,:-1] = self.weighted_adjacency_matrix\n",
    "        self.weighted_adjacency_matrix =np.copy(temp_matrix)\n",
    "        \n",
    "    def attach_vertex(self, new_vertex, existing_vertex, weight):\n",
    "        new_edge = edge(new_vertex, existing_vertex, weight)\n",
    "        self.edges.append(new_edge)\n",
    "        \n",
    "        self.dictio[new_vertex.name]=len(self.vertices)\n",
    "        self.vertices.append(new_vertex)\n",
    "        \n",
    "        #append a column and a row to the symmetric adjacency matrix, where the (new_vertex, existing_vertex) entries\n",
    "        #are updated with weight, everything else set to zero\n",
    "        \n",
    "        #dictionary of names to indices makes the substitution straightforward\n",
    "             \n",
    "        # new matrix with an extra row and column\n",
    "        a = (len(self.vertices), len(self.vertices))\n",
    "        temp_matrix = np.zeros(a)\n",
    "        # copy the weight to the appropriate place\n",
    "        temp_matrix[self.dictio[new_vertex.name],self.dictio[existing_vertex.name]] = weight\n",
    "        #and vice-versa\n",
    "        temp_matrix[self.dictio[existing_vertex.name],self.dictio[new_vertex.name]] = weight\n",
    "        #and copy the old matrix entries onto the new matriz entries\n",
    "        temp_matrix[:-1,:-1] = self.weighted_adjacency_matrix\n",
    "        self.weighted_adjacency_matrix =np.copy(temp_matrix)  \n",
    "            \n",
    "        \n",
    "        ###########################NEEDS UPDATE################################\n",
    "        \n",
    "    def attach_vertex_randomly(self, new_vertex, min_neighbours, max_neighbours):\n",
    "        #needs work since I coded the adjacency matrix\n",
    "        #needs weight range as well\n",
    "        #needs to be seed-able\n",
    "        # The idea is getting a 'natural' graph with control over connectivity, but \n",
    "        # not forcing an equal number of edges on each vertex\n",
    "        \"\"\"method that adds a vertex to an existing graph by attaching it\n",
    "        to a random (within a range) number of existing vertices. If called iteratively with the same \n",
    "        parameters, should generate a graph with connectivity approximately (max_neighbours-min_neighbours)/2\"\"\"\n",
    "        for a in sample(self.vertices,choice(range(max(1, min_neighbours),min(max_neighbours,len(self.vertices))))):\n",
    "            self.edges.append(edge(new_vertex, a, random()))\n",
    "        self.vertices.append(new_vertex)\n",
    "    \n",
    "    def attach_vertex_list_randomly(self, vertex_list, min_neighbours, max_neighbours):\n",
    "        \"\"\"method that adds a list of vertices to an existing graph, using attach_vertex_randomly\"\"\"\n",
    "        #probably okay, as long as I get the random version to play nice with \n",
    "        for v in vertex_list:\n",
    "            self.attach_vertex_randomly(vertex(v), min_neighbours, max_neighbours)\n",
    "            \n",
    "    def print(self):\n",
    "        #just for myself, should be properly formatted and more info. \n",
    "        print(len(self.vertices), \"VERTICES:\")\n",
    "        for a in self.vertices:\n",
    "            a.print()\n",
    "        print(len(self.edges), \"EDGES:\")\n",
    "        for a in self.edges:\n",
    "            a.print()\n",
    "            \n",
    "        ##########################NEEDS IMPLEMENTING#############################\n",
    "        \n",
    "    def attach_edge(self, vertex1, vertex2, weight):\n",
    "        #Marco's request?\n",
    "        #between existing vertices: update adjacency matrix(v1,v2) with a different weight\n",
    "        a\n",
    "    \n",
    "    def remove_edge(self, vertex1, vertex2):\n",
    "        #Marco's request?\n",
    "        #update the adjacency matrix(v1,v2) entry with zero\n",
    "        a\n",
    "        #remove one or more vertices if necessary\n",
    "                  \n",
    "    def random_network(self, number_of_nodes, weights, connectedness, seed):\n",
    "        #what other inputs do we need here?\n",
    "        a\n",
    "        \n",
    "    def attach_vertex_fully_connected(self, vertex, weight_function):\n",
    "        # used to build fully connected graphs (Heidelberg)\n",
    "        a\n",
    "        \n",
    "    def attach_vertex_from_Heidelberg(distance2D):\n",
    "        #for each line in file\n",
    "          #read coordinates to name vertex, then attach vertex to all other vertices, using attach_vertex_fully_connected\n",
    "            #and using euclidean distance as weight function            \n",
    "            a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 VERTICES:\n",
      "Cairo\n",
      "Paris\n",
      "1 EDGES:\n",
      "Cairo to Paris taking 0.5 km\n"
     ]
    }
   ],
   "source": [
    "first_graph = graph(vertex(\"Cairo\"),vertex(\"Paris\"),0.5)\n",
    "first_graph.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 VERTICES:\n",
      "Cairo\n",
      "Paris\n",
      "Saint Etienne\n",
      "2 EDGES:\n",
      "Cairo to Paris taking 0.5 km\n",
      "Saint Etienne to Cairo taking 2 km\n"
     ]
    }
   ],
   "source": [
    "first_graph.attach_vertex(vertex(\"Saint Etienne\"), vertex(\"Cairo\"),2)\n",
    "first_graph.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.5, 2. ],\n",
       "       [0.5, 0. , 0. ],\n",
       "       [2. , 0. , 0. ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_graph.weighted_adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 VERTICES:\n",
      "Cairo\n",
      "Paris\n",
      "Saint Etienne\n",
      "Mumbai\n",
      "London\n",
      "Madrid\n",
      "Lyon\n",
      "New York\n",
      "Moscow\n",
      "Tokyo\n",
      "Heidelberg\n",
      "Quito\n",
      "Hanoi\n",
      "Ankara\n",
      "30 EDGES:\n",
      "Cairo to Paris taking 0.5 km\n",
      "Saint Etienne to Cairo taking 2 km\n",
      "Mumbai to Paris taking 0.8103329694825201 km\n",
      "Mumbai to Cairo taking 0.799437875405273 km\n",
      "London to Paris taking 0.6791345943128114 km\n",
      "London to Mumbai taking 0.6759317842367751 km\n",
      "London to Cairo taking 0.20124191424555382 km\n",
      "Madrid to Cairo taking 0.38983182281836093 km\n",
      "Madrid to Mumbai taking 0.6564618791102279 km\n",
      "Madrid to London taking 0.313568013257415 km\n",
      "Lyon to Mumbai taking 0.22911562229275917 km\n",
      "Lyon to Saint Etienne taking 0.8682208318841873 km\n",
      "Lyon to London taking 0.23673798389484924 km\n",
      "New York to Lyon taking 0.6891455644565597 km\n",
      "New York to Cairo taking 0.7408191641171293 km\n",
      "New York to Paris taking 0.7175700601334056 km\n",
      "Moscow to Mumbai taking 0.6409386144995696 km\n",
      "Moscow to Lyon taking 0.5171636951864105 km\n",
      "Tokyo to Madrid taking 0.8643714066475541 km\n",
      "Tokyo to Cairo taking 0.1602403532815524 km\n",
      "Heidelberg to Moscow taking 0.21140116405303877 km\n",
      "Heidelberg to Paris taking 0.8476827334378756 km\n",
      "Heidelberg to Cairo taking 0.4838242720341629 km\n",
      "Quito to Heidelberg taking 0.42203564442018204 km\n",
      "Quito to Cairo taking 0.6663338906134076 km\n",
      "Hanoi to Saint Etienne taking 0.5929269370159932 km\n",
      "Hanoi to Cairo taking 0.3857729018711875 km\n",
      "Hanoi to Moscow taking 0.41513843763660163 km\n",
      "Ankara to New York taking 0.40470835402614125 km\n",
      "Ankara to Hanoi taking 0.27468000950940685 km\n"
     ]
    }
   ],
   "source": [
    "#does not update adjancency matrix -- just for kicks\n",
    "cities = ['Mumbai', 'London', 'Madrid', 'Lyon', 'New York','Moscow', 'Tokyo', 'Heidelberg', 'Quito', 'Hanoi', 'Ankara' ]\n",
    "first_graph.attach_vertex_list_randomly(cities, min_neighbours=2, max_neighbours=4)\n",
    "first_graph.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.5, 2. ],\n",
       "       [0.5, 0. , 0. ],\n",
       "       [2. , 0. , 0. ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_graph.weighted_adjacency_matrix"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Anaconda3]",
   "language": "python",
   "name": "Python [Anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
